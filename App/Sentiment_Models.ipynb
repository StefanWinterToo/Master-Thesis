{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VADER: https://towardsdatascience.com/sentiment-analysis-in-10-minutes-with-rule-based-vader-and-nltk-72067970fb71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cleaned_submissions():\n",
    "    data = pd.read_pickle(\"./data/cleaned_submissions.pkl\")\n",
    "    data = data.loc[data[\"sentiment\"] != \"\", [\"text\", \"sentiment\"]] # Only get labeled instances\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_vectorize_data(data):\n",
    "    # Encode labels\n",
    "    lenc = LabelEncoder()\n",
    "    y = lenc.fit_transform(data[\"sentiment\"])\n",
    "\n",
    "    # Vectorize text using tfidf\n",
    "    tfidf = TfidfVectorizer(preprocessor=' '.join, lowercase=False, min_df=5) # min_df = Minimum occurance of words\n",
    "    X = tfidf.fit_transform(data[\"text\"])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sparse_matrices():\n",
    "    X = scipy.sparse.load_npz('./data/X_sparse.npz')\n",
    "    y = np.load(\"./data/y_sparse.npy\")\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(X, y):\n",
    "    # Train-Test Split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=Pipeline(steps=[('svc', SVC())]),\n",
       "             param_grid={'svc__C': [3], 'svc__kernel': ['poly']})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "pipeline = Pipeline([\n",
    "        (\"svc\", SVC())\n",
    "    ])\n",
    "\n",
    "param_grid = {\"svc__kernel\": [\"poly\"], \"svc__C\": [3]} #[\"poly\", \"rbf\", \"sigmoid\", \"linear\"], [3, 4, 5, 6, 7]\n",
    "CV = GridSearchCV(pipeline, param_grid, cv = 5)\n",
    "# pipeline.get_params().keys() See all available parameters\n",
    "CV.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(CV, open(\"./data/svm_first_model_poly_3.sav\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(\"./data/svm_first_model_poly_3.sav\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 0.8837895792141246 can be achieved with the following parameters: {'svc__C': 3, 'svc__kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of {} can be achieved with the following parameters: {}\".format(loaded_model.score(X_test, y_test), CV.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_cleaned_submissions()\n",
    "X, y = load_sparse_matrices()\n",
    "X_train, X_test, y_train, y_test = split_train_test(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\DEV\\Master Thesis\\App\\.thesis\\lib\\site-packages\\sklearn\\naive_bayes.py:508: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n",
      "c:\\DEV\\Master Thesis\\App\\.thesis\\lib\\site-packages\\sklearn\\naive_bayes.py:508: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n",
      "c:\\DEV\\Master Thesis\\App\\.thesis\\lib\\site-packages\\sklearn\\naive_bayes.py:508: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n",
      "c:\\DEV\\Master Thesis\\App\\.thesis\\lib\\site-packages\\sklearn\\naive_bayes.py:508: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n",
      "c:\\DEV\\Master Thesis\\App\\.thesis\\lib\\site-packages\\sklearn\\naive_bayes.py:508: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n",
      "c:\\DEV\\Master Thesis\\App\\.thesis\\lib\\site-packages\\sklearn\\naive_bayes.py:508: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n",
      "c:\\DEV\\Master Thesis\\App\\.thesis\\lib\\site-packages\\sklearn\\naive_bayes.py:508: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n",
      "c:\\DEV\\Master Thesis\\App\\.thesis\\lib\\site-packages\\sklearn\\naive_bayes.py:508: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n",
      "c:\\DEV\\Master Thesis\\App\\.thesis\\lib\\site-packages\\sklearn\\naive_bayes.py:508: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n",
      "c:\\DEV\\Master Thesis\\App\\.thesis\\lib\\site-packages\\sklearn\\naive_bayes.py:508: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=Pipeline(steps=[('mnb', MultinomialNB())]),\n",
       "             param_grid={'mnb__alpha': array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]),\n",
       "                         'mnb__fit_prior': [True, False]})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "pipeline = Pipeline([\n",
    "        (\"mnb\", MultinomialNB())\n",
    "    ])\n",
    "\n",
    "param_grid = {\"mnb__alpha\": np.arange(0, 1, 0.1), \"mnb__fit_prior\": [True, False]}\n",
    "CV = GridSearchCV(pipeline, param_grid, cv = 5)\n",
    "# pipeline.get_params().keys() See all available parameters\n",
    "CV.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(CV, open(\"./data/nb_first_model_mnb.sav\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(\"./data/nb_first_model_mnb.sav\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 0.7941741624662341 can be achieved with the following parameters: {'mnb__alpha': 0.6000000000000001, 'mnb__fit_prior': False}\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of {} can be achieved with the following parameters: {}\".format(loaded_model.score(X_test, y_test), CV.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.86      0.69      5144\n",
      "           1       0.95      0.77      0.85     22421\n",
      "           2       0.68      0.82      0.74      8344\n",
      "\n",
      "    accuracy                           0.79     35909\n",
      "   macro avg       0.74      0.82      0.76     35909\n",
      "weighted avg       0.83      0.79      0.80     35909\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = CV.predict(X_test)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin DEV #\n",
    "# This DEV actually works!!! Use this!!!\n",
    "# https://stackoverflow.com/questions/42064690/using-pre-trained-word2vec-with-lstm-for-word-generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_cleaned_submissions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "lenc = LabelEncoder()\n",
    "y_train = lenc.fit_transform(data[\"sentiment\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = data[\"text\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2934\n"
     ]
    }
   ],
   "source": [
    "max_sentence_len = 0\n",
    "for sentence in sentences:\n",
    "    if len(sentence) > max_sentence_len:\n",
    "        max_sentence_len = len(sentence)\n",
    "print(max_sentence_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.quora.com/What-are-the-strategies-to-deal-with-different-length-of-sentences-for-RNN-or-LSTM\n",
    "1) If the sentences are too long, try to create an embedding that maps the words to a smaller feature space. Take a look at GloVe embeddings, Word2Vec, etc.\n",
    "\n",
    "2) Increase the depth of the RNN. As the sequence length gets longer, it becomes harder and harder for a single layered LSTM to process the dependencies in the data. Adding more hidden layers greatly helps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually set it lower, because 2934 words in a sentence is quite a lot!!!\n",
    "max_sentence_len = 90 # set it to 100 to have less dimensions for dev purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sentences = []\n",
    "for sentence in sentences:\n",
    "    new_sentences.append(sentence[:max_sentence_len])\n",
    "sentences = new_sentences\n",
    "del new_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "word_model = gensim.models.Word2Vec(sentences, vector_size=200, min_count=1, window=5) # Vector_size = number of words??? Check params!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_weights = word_model.wv.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size, emdedding_size =pretrained_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  moon -> ðŸ˜© (0.98), mooning (0.97), rocket (0.97), gent (0.96), baby (0.96), brrr (0.96), plntr (0.95), cmon (0.95)\n",
      "  short -> 138 (0.94), interest (0.93), unwind (0.93), 22642 (0.93), cover (0.93), gamma (0.92), float (0.92), vix (0.92)\n",
      "  robinhood -> app (0.98), webull (0.98), 212 (0.98), allow (0.98), uk (0.98), rh (0.98), trade (0.98), purchase (0.97)\n",
      "  andromeda -> mars (0.99), girl (0.99), goin (0.99), gang (0.99), pluto (0.99), baby (0.99), retards (0.98), ðŸŒ› (0.98)\n",
      "  ape -> fellow (0.98), autist (0.94), retard (0.94), loyal (0.94), together (0.93), strong (0.93), fledged (0.92), brother (0.92)\n",
      "  ðŸ¦ -> ðŸ™ (0.98), ðŸ¦§ (0.98), ðŸ’ª (0.98), ðŸ¤ (0.98), âœ‹ (0.97), ðŸŒ (0.97), ðŸ» (0.97), strong (0.97)\n"
     ]
    }
   ],
   "source": [
    "for word in ['moon', 'short', 'robinhood', 'andromeda', 'ape', 'ðŸ¦']:\n",
    "  most_similar = ', '.join('%s (%.2f)' % (similar, dist) \n",
    "                           for similar, dist in word_model.wv.most_similar(word)[:8])\n",
    "  print('  %s -> %s' % (word, most_similar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2idx(word):\n",
    "  return word_model.wv.key_to_index[word]\n",
    "def idx2word(idx):\n",
    "  return word_model.wv.index_to_key[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_lstm = np.zeros([len(sentences), max_sentence_len], dtype=np.int32)\n",
    "y_train_lstm = np.zeros([len(sentences)], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sentence in enumerate(sentences):\n",
    "  for t, word in enumerate(sentence):\n",
    "    x_train_lstm[i, t] = word2idx(word)\n",
    "  #y_train_lstm[i] = word2idx(sentence[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 bullish [0. 1. 0.]\n",
      "2 neutral [0. 0. 1.]\n",
      "0 bearish [1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0], data[\"sentiment\"][0], to_categorical(y_train)[0])\n",
    "print(y_train[-2], list(data[\"sentiment\"])[-2], to_categorical(y_train)[-2])\n",
    "print(y_train[6], data[\"sentiment\"][60], to_categorical(y_train)[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_lstm, X_test_lstm, y_train, y_test = split_train_test(x_train_lstm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "180/180 - 3s - loss: 1.0310 - acc: 0.5086 - val_loss: 1.0110 - val_acc: 0.5301 - 3s/epoch - 19ms/step\n",
      "Epoch 2/20\n",
      "180/180 - 3s - loss: 1.0203 - acc: 0.5190 - val_loss: 1.0097 - val_acc: 0.5301 - 3s/epoch - 14ms/step\n",
      "Epoch 3/20\n",
      "180/180 - 3s - loss: 1.0176 - acc: 0.5190 - val_loss: 1.0101 - val_acc: 0.5298 - 3s/epoch - 14ms/step\n",
      "Epoch 4/20\n",
      "180/180 - 2s - loss: 1.0115 - acc: 0.5239 - val_loss: 1.0128 - val_acc: 0.5301 - 2s/epoch - 14ms/step\n",
      "Epoch 5/20\n",
      "180/180 - 2s - loss: 0.9937 - acc: 0.5349 - val_loss: 1.0332 - val_acc: 0.5259 - 2s/epoch - 14ms/step\n",
      "Epoch 6/20\n",
      "180/180 - 2s - loss: 0.9296 - acc: 0.5528 - val_loss: 0.9398 - val_acc: 0.5465 - 2s/epoch - 14ms/step\n",
      "Epoch 7/20\n",
      "180/180 - 2s - loss: 0.7553 - acc: 0.6565 - val_loss: 0.9307 - val_acc: 0.5698 - 2s/epoch - 14ms/step\n",
      "Epoch 8/20\n",
      "180/180 - 2s - loss: 0.6059 - acc: 0.7346 - val_loss: 0.9794 - val_acc: 0.5948 - 2s/epoch - 14ms/step\n",
      "Epoch 9/20\n",
      "180/180 - 2s - loss: 0.4695 - acc: 0.8148 - val_loss: 1.2022 - val_acc: 0.5917 - 2s/epoch - 14ms/step\n",
      "Epoch 10/20\n",
      "180/180 - 2s - loss: 0.3645 - acc: 0.8650 - val_loss: 1.2549 - val_acc: 0.6223 - 2s/epoch - 14ms/step\n",
      "Epoch 11/20\n",
      "180/180 - 2s - loss: 0.3174 - acc: 0.8805 - val_loss: 1.2935 - val_acc: 0.5994 - 2s/epoch - 13ms/step\n",
      "Epoch 12/20\n",
      "180/180 - 2s - loss: 0.2796 - acc: 0.8962 - val_loss: 1.4822 - val_acc: 0.5976 - 2s/epoch - 13ms/step\n",
      "Epoch 13/20\n",
      "180/180 - 3s - loss: 0.2593 - acc: 0.9044 - val_loss: 1.5424 - val_acc: 0.5799 - 3s/epoch - 15ms/step\n",
      "Epoch 14/20\n",
      "180/180 - 3s - loss: 0.2358 - acc: 0.9111 - val_loss: 1.7495 - val_acc: 0.6063 - 3s/epoch - 15ms/step\n",
      "Epoch 15/20\n",
      "180/180 - 3s - loss: 0.2179 - acc: 0.9217 - val_loss: 1.7044 - val_acc: 0.5907 - 3s/epoch - 14ms/step\n",
      "Epoch 16/20\n",
      "180/180 - 2s - loss: 0.2045 - acc: 0.9268 - val_loss: 1.7684 - val_acc: 0.5882 - 2s/epoch - 14ms/step\n",
      "Epoch 17/20\n",
      "180/180 - 2s - loss: 0.1907 - acc: 0.9303 - val_loss: 1.6844 - val_acc: 0.5861 - 2s/epoch - 13ms/step\n",
      "Epoch 18/20\n",
      "180/180 - 2s - loss: 0.1835 - acc: 0.9347 - val_loss: 2.1657 - val_acc: 0.5785 - 2s/epoch - 13ms/step\n",
      "Epoch 19/20\n",
      "180/180 - 2s - loss: 0.1670 - acc: 0.9389 - val_loss: 1.9518 - val_acc: 0.5966 - 2s/epoch - 13ms/step\n",
      "Epoch 20/20\n",
      "180/180 - 2s - loss: 0.1528 - acc: 0.9447 - val_loss: 2.0174 - val_acc: 0.5701 - 2s/epoch - 13ms/step\n"
     ]
    }
   ],
   "source": [
    "acc = []\n",
    "val_acc = []\n",
    "loss = []\n",
    "val_loss = []\n",
    "\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim = vocab_size, output_dim = emdedding_size, weights = [pretrained_weights]))\n",
    "    model.add(CuDNNLSTM(units = emdedding_size))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(3, activation = \"softmax\"))\n",
    "    model.compile(\"adam\", \"categorical_crossentropy\", metrics = [\"acc\"])\n",
    "    return model\n",
    "\n",
    "model = build_model()\n",
    "history = model.fit(x_train_lstm, y_train, epochs=20, validation_split=0.2, batch_size=64, verbose=2)\n",
    "acc.append(history.history['acc'])\n",
    "val_acc.append(history.history['val_acc'])\n",
    "loss.append(history.history['loss'])\n",
    "val_loss.append(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc_history = history.history[\"acc\"]\n",
    "val_acc_history = history.history[\"val_acc\"]\n",
    "\n",
    "plt.plot(range(1, len(acc_history) + 1), acc_history)\n",
    "plt.plot(range(1, len(val_acc_history) + 1), val_acc_history)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend([\"training\", \"validation\"])\n",
    "plt.show()\n",
    "\n",
    "loss_history = history.history[\"loss\"]\n",
    "val_loss_history = history.history[\"val_loss\"]\n",
    "\n",
    "plt.plot(range(1, len(loss_history) + 1), loss_history)\n",
    "plt.plot(range(1, len(val_loss_history) + 1), val_loss_history)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend([\"training\", \"validation\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model.predict(X_test_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(test_pred[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08388852, 0.25641242, 0.6596991 ], dtype=float32)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(test_pred[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_test_pred = []\n",
    "for i in range(len(test_pred)):\n",
    "    maxi = np.argmax(test_pred[i])\n",
    "    arr = np.zeros((3))\n",
    "    arr[maxi] = 1\n",
    "    converted_test_pred.append(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.43      0.46       723\n",
      "           1       0.69      0.62      0.65      1871\n",
      "           2       0.41      0.53      0.47       997\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      3591\n",
      "   macro avg       0.53      0.53      0.53      3591\n",
      "weighted avg       0.57      0.56      0.56      3591\n",
      " samples avg       0.56      0.56      0.56      3591\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, converted_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "180/180 - 31s - loss: 1.0326 - acc: 0.5154 - val_loss: 1.0134 - val_acc: 0.5301 - 31s/epoch - 175ms/step\n",
      "Epoch 2/7\n",
      "180/180 - 26s - loss: 1.0201 - acc: 0.5190 - val_loss: 1.0134 - val_acc: 0.5301 - 26s/epoch - 144ms/step\n",
      "Epoch 3/7\n",
      "180/180 - 3s - loss: 1.0165 - acc: 0.5191 - val_loss: 1.0104 - val_acc: 0.5301 - 3s/epoch - 15ms/step\n",
      "Epoch 4/7\n",
      "180/180 - 3s - loss: 1.0106 - acc: 0.5236 - val_loss: 1.0171 - val_acc: 0.5245 - 3s/epoch - 14ms/step\n",
      "Epoch 5/7\n",
      "180/180 - 3s - loss: 0.9919 - acc: 0.5350 - val_loss: 1.0357 - val_acc: 0.5280 - 3s/epoch - 14ms/step\n",
      "Epoch 6/7\n",
      "180/180 - 13s - loss: 0.9177 - acc: 0.5494 - val_loss: 0.9539 - val_acc: 0.5468 - 13s/epoch - 70ms/step\n",
      "Epoch 7/7\n",
      "180/180 - 15s - loss: 0.7184 - acc: 0.6630 - val_loss: 1.0004 - val_acc: 0.5600 - 15s/epoch - 82ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22c5b1b8550>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Without loop\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dense, CuDNNLSTM, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim = vocab_size, output_dim = emdedding_size, weights = [pretrained_weights]))\n",
    "model.add(CuDNNLSTM(units = emdedding_size))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(3, activation = \"softmax\"))\n",
    "model.compile(\"adam\", \"categorical_crossentropy\", metrics = [\"acc\"])\n",
    "model.fit(x_train_lstm, y_train, epochs=7, validation_split=0.2, batch_size=64, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, None, 200)         4268200   \n",
      "                                                                 \n",
      " cu_dnnlstm_1 (CuDNNLSTM)    (None, 200)               321600    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 603       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,590,403\n",
      "Trainable params: 4,590,403\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End DEV #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_sparse_matrices()\n",
    "X_train, X_test, y_train, y_test = split_train_test(X, y)\n",
    "del X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/device:GPU:0\n",
      "Num GPUs Available:  1\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.test.gpu_device_name())\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten array\n",
    "# Limit Size for DEV\n",
    "X_train_lstm = X_train.toarray()[:10000, :, None]\n",
    "# y_train_lstm = to_categorical(y_train) # To make it 2d\n",
    "# y_train_lstm = y_train_lstm[:10000, :]\n",
    "y_train_lstm = y_train[:10000]\n",
    "# del X_train\n",
    "# del y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0\n",
      "Num GPUs Available:  1\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices(\"GPU\")))\n",
    "print(tf.config.list_physical_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "  tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "  # Invalid device or cannot modify virtual devices once initialized.\n",
    "  pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\DEV\\Master Thesis\\App\\.thesis\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass classes=[0 1 2], y=[1 1 1 ... 1 1 1] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import compute_class_weight\n",
    "classWeight = compute_class_weight('balanced', np.unique(y_train_lstm), y_train_lstm) \n",
    "classWeight = dict(enumerate(classWeight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 2.440214738897023, 1: 0.5340168749332479, 2: 1.3935340022296545}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classWeight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\DEV\\Master Thesis\\App\\.thesis\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\DEV\\Master Thesis\\App\\.thesis\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\DEV\\Master Thesis\\App\\.thesis\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\DEV\\Master Thesis\\App\\.thesis\\lib\\site-packages\\keras\\engine\\training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\DEV\\Master Thesis\\App\\.thesis\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\DEV\\Master Thesis\\App\\.thesis\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 213, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"sequential_10\" (type Sequential).\n    \n    Input 0 of layer \"cu_dnnlstm_10\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 2050)\n    \n    Call arguments received:\n      â€¢ inputs=<tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x00000206DECB8040>\n      â€¢ training=True\n      â€¢ mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15632/3843339595.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"softmax\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopti\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[1;34m\"categorical_crossentropy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassWeight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\DEV\\Master Thesis\\App\\.thesis\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\DEV\\Master Thesis\\App\\.thesis\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1127\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1128\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1129\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1130\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\DEV\\Master Thesis\\App\\.thesis\\lib\\site-packages\\keras\\engine\\training.py\", line 878, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\DEV\\Master Thesis\\App\\.thesis\\lib\\site-packages\\keras\\engine\\training.py\", line 867, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\DEV\\Master Thesis\\App\\.thesis\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\DEV\\Master Thesis\\App\\.thesis\\lib\\site-packages\\keras\\engine\\training.py\", line 808, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\DEV\\Master Thesis\\App\\.thesis\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\DEV\\Master Thesis\\App\\.thesis\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 213, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"sequential_10\" (type Sequential).\n    \n    Input 0 of layer \"cu_dnnlstm_10\" is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 2050)\n    \n    Call arguments received:\n      â€¢ inputs=<tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x00000206DECB8040>\n      â€¢ training=True\n      â€¢ mask=None\n"
     ]
    }
   ],
   "source": [
    "# DEV\n",
    "#from keras.optimizers import adam\n",
    "#opt = SGD(lr=0.01)\n",
    "\n",
    "from keras.layers import Embedding, Dense, CuDNNLSTM, Dropout\n",
    "import tensorflow as tf\n",
    "opti = tf.keras.optimizers.Adam(0.1)\n",
    "\n",
    "m = Sequential()\n",
    "# m.add(Embedding(X_train_lstm.shape[1], 512)) # Input dim is X_train_lstm.shape[1], dim is the output dimensionality\n",
    "m.add(CuDNNLSTM(32))\n",
    "m.add(Dropout(0.1))\n",
    "m.add(Dense(1, activation = \"softmax\"))\n",
    "m.compile(optimizer = opti, loss =  \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "history = m.fit(X_train, y_train, epochs=5, batch_size=64, verbose=2, class_weight = classWeight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dense, CuDNNLSTM, Dropout\n",
    "\n",
    "def build_model(input_dim, output_dim, hidden_states, opt):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim, output_dim)) # Input dim is X_train_lstm.shape[1], dim is the output dimensionality\n",
    "    model.add(CuDNNLSTM(hidden_states))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(3, activation = \"softmax\"))\n",
    "    model.compile(opt, \"categorical_crossentropy\", metrics = [\"acc\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "125/125 - 12s - loss: 0.9262 - acc: 0.6177 - val_loss: 0.8930 - val_acc: 0.6345 - 12s/epoch - 98ms/step\n",
      "Epoch 2/5\n",
      "125/125 - 11s - loss: 0.9168 - acc: 0.6216 - val_loss: 0.8927 - val_acc: 0.6345 - 11s/epoch - 92ms/step\n",
      "Epoch 3/5\n",
      "125/125 - 11s - loss: 0.9158 - acc: 0.6216 - val_loss: 0.8937 - val_acc: 0.6345 - 11s/epoch - 91ms/step\n",
      "Epoch 4/5\n",
      "125/125 - 12s - loss: 0.9145 - acc: 0.6216 - val_loss: 0.8932 - val_acc: 0.6345 - 12s/epoch - 92ms/step\n",
      "Epoch 5/5\n",
      "125/125 - 11s - loss: 0.9156 - acc: 0.6216 - val_loss: 0.8928 - val_acc: 0.6345 - 11s/epoch - 91ms/step\n"
     ]
    }
   ],
   "source": [
    "dim = [512] #[256, 512, 1024]\n",
    "hidden_states = [16] #[16, 32, 64]\n",
    "optimi = [\"Adam\"] #[\"rmsprop\", \"SGD\", \"Adam\"]\n",
    "\n",
    "acc = []\n",
    "val_acc = []\n",
    "loss = []\n",
    "val_loss = []\n",
    "\n",
    "param_list = []\n",
    "\n",
    "for d in dim:\n",
    "    for state in hidden_states:\n",
    "        for opt in optimi:\n",
    "            # optimizer = tf.keras.optimizers.Adam(0.001)\n",
    "            # optimizer.learning_rate.assign(0.01)\n",
    "            model = build_model(X_train_lstm.shape[1], d, state, opt)\n",
    "            history = model.fit(X_train_lstm, y_train_lstm, epochs=5, batch_size=64, validation_split=0.2, verbose=2)\n",
    "            acc.append(history.history['acc'])\n",
    "            val_acc.append(history.history['val_acc'])\n",
    "            loss.append(history.history['loss'])\n",
    "            val_loss.append(history.history['val_loss'])\n",
    "            param_list.append(\"Optimizer: \" + opt + \" - States: \" + str(state) + \" - Dimensions:\" + str(d))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_3 (Embedding)     (None, None, 512)         1049600   \n",
      "                                                                 \n",
      " cu_dnnlstm_3 (CuDNNLSTM)    (None, 32)                69888     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,119,521\n",
      "Trainable params: 1,119,521\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "from keras.models import load_model\n",
    "history.model.save('./data/small_lstm_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load_model('./data/small_lstm_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(loaded_model.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(loaded_model.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.0, 0.0], 'acc': [0.6518188714981079, 0.6518188714981079]}\n",
      "{'verbose': 0, 'epochs': 2, 'steps': 4489}\n"
     ]
    }
   ],
   "source": [
    "print(history.history) # Loss and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./data/train_history', 'wb') as file_pi:\n",
    "    pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/train_history', 'rb') as file_pi:\n",
    "    h = pickle.load(file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [0.0, 0.0], 'acc': [0.6518188714981079, 0.6518188714981079]}\n"
     ]
    }
   ],
   "source": [
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_history(data_list, label_list, title, xlabel='Epochs', ylabel=None):\n",
    "    ''' Plots a list of vectors.\n",
    "\n",
    "    Parameters:\n",
    "        data_list  : list of vectors containing the values to plot\n",
    "        label_list : list of labels describing the data, one per vector\n",
    "        title      : title of the plot\n",
    "        ylabel     : label for the y axis\n",
    "    '''\n",
    "    epochs = range(1, len(data_list[0]) + 1)\n",
    "\n",
    "    for data, label in zip(data_list, label_list):\n",
    "        plt.plot(epochs, data, label=label)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9328/1180918268.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m plot_history(data_list=val_loss,\n\u001b[0m\u001b[0;32m      2\u001b[0m              \u001b[0mlabel_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m#param_list,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m              \u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Comparison of different recurrent layer types'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m              ylabel='Loss')\n\u001b[0;32m      5\u001b[0m plot_history(data_list=val_acc,\n",
      "\u001b[1;31mNameError\u001b[0m: name 'val_loss' is not defined"
     ]
    }
   ],
   "source": [
    "plot_history(data_list=val_loss,\n",
    "             label_list=[[\"\"]*len(param_list)], #param_list,\n",
    "             title='Comparison of different recurrent layer types',\n",
    "             ylabel='Loss')\n",
    "plot_history(data_list=val_acc,\n",
    "             label_list=[[\"\"]*len(param_list)], #param_list,\n",
    "             title='Comparison of different recurrent layer types',\n",
    "             ylabel='Validation accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a199850fbe9b2f1658a16eea735881451fc009eba53b7dda86327ce82228d5dd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('.thesis': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
