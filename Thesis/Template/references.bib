@book{mackay2003information,
  title={Information theory, inference and learning algorithms},
  author={MacKay, David JC and Mac Kay, David JC},
  year={2003},
  publisher={Cambridge university press}
}

@book{raschka2019pythonmachinelearning,
  title={Python Machine Learning},
  author={Raschka Sebastian and Mirjalili Vahid},
  year={2019},
  publisher={Packt Publishing}
}

@article{minsky1961steps,
  title={Steps toward artificial intelligence},
  author={Minsky, Marvin},
  journal={Proceedings of the IRE},
  volume={49},
  number={1},
  pages={8-30},
  year={1961},
  publisher={IEEE}
}

@article{ananny2018seeing,
  title={Seeing without knowing: Limitations of the transparency ideal and its application to algorithmic accountability},
  author={Ananny, Mike and Crawford, Kate},
  journal={New Media \& Society},
  volume={20},
  number={3},
  pages={973--989},
  year={2018},
  publisher={SAGE Publications Sage UK: London, England}
}

@article{lyocsa2021yolotrading,
  title={YOLO trading: Riding with the herd during the GameStop episode},
  author={Lyócsa Štefan, Baumöhl Eduard and Vyrost Tomáš},
  journal={Finance Research Letters},
  year={2021}
}

@article{anand2021WallstreetbetsAgainstWallstreet,
  title={WallStreetBets Against Wall Street: The Role of Reddit in the GameStop Short Squeeze},
  author={Anand Abhinav and Pathak Jalaj},
  journal={Indian Institute of Management Bangalore Research Paper Series},
  year={2021}
}

@article{danbolt2015InvestorSentiment,
  title={Investor sentiment and bidder announcement abnormal returns},
  author={Danbolt Jo, Siganos Antonios and Vagenas-Nanos Evangelos},
  journal={Journal of Corporate Finance},
  year={2015},
  pages={164-179}
}

@article{long2021LikeTheStock,
  title={'I Just Like the Stock' versus 'Fear and Loathing on Main Street': The Role of Reddit Sentiment in the GameStop Short Squeeze},
  author={Long Cheng, Lucey Brian M and Yarovaya Larisa},
  journal={SSRN Electronic Journal},
  year={2021}
}

@article{park2015EfficientExtractionOfDomain,
  title={Efficient extraction of domain specific sentiment lexicon with active learning},
  author={Park Sungrae, Lee Wonsung and Moon Il-Chul},
  journal={Pattern Recognition Letters},
  year={2015},
  pages={38-44}
}

@article{jemai2021SentimentAnalysis,
  title={Sentiment Analysis Using Machine Learning Algorithms},
  author={Jemai Fatma, Hayouni Mohamed and Baccar Sahbi},
  journal={International Wireless Communications and Mobile Computing},
  year={2021},
  pages={775-779}
}

@article{fu2018lexiconenhancedlstm,
  title={Lexicon Enhanced LSTM With Attention for General Sentiment Analysis},
  author={Fu Xianghua, Yang Jingying, Li Jainqiang and Fang Min and Wang Huihui},
  journal={IEEE Access},
  year={2018},
  pages={71884-71891}
}

@article{das2007yahoo,
  title={Yahoo! for Amazon: Sentiment Extraction from Small Talk on the Web},
  author={Das Sanjiv R. and Chen Mike Y.},
  journal={Management Science},
  year={2007},
  pages={1375-1388}
}

@article{umar2021ataleofcompanyfundamentals,
  title={A tale of company fundamentals vs sentiment driven pricing: The case of GameStop},
  author={Umar Zaghum, Gubareva Mariya, Yousaf Imran and Ali Shoaib},
  journal={Journal of Behavioral and Experimental Finance},
  year={2021}
}

@article{park2015EfficientExtraction,
  title = {Efficient extraction of domain specific sentiment lexicon with active learning},
  journal = {Pattern Recognition Letters},
  volume = {56},
  pages = {38-44},
  year = {2015},
  issn = {0167-8655},
  author = {Sungrae Park, Wonsung Lee and Il-Chul Moon},
  keywords = {Sentiment analysis, Active learning, Sentiment lexicon},
  abstract = {Recent research indicates that a sentiment lexicon focusing on a specific domain leads to better sentiment analyses compared to a general-purpose sentiment lexicon, such as SentiWordNet. In spite of this potential improvement, the cost of building a domain-specific sentiment lexicon hinders its wider and more practical applications. To compensate for this difficulty, we propose extracting a sentiment lexicon from a domain-specific corpus by annotating an intelligently selected subset of documents in the corpus. Specifically, the subset is selected by an active learner with initializations from diverse text analytics, i.e. latent Dirichlet allocation and our proposed lexicon coverage algorithm. This active learning produces a better domain-specific sentiment lexicon which results in a higher accuracy of the sentiment classification. Subsequently, we evaluate extracted sentiment lexicons by observing (1) the increased F1 measure in sentiment classifications and (2) the increased similarity to the sentiment lexicon with the full annotation. We expect that this contribution will enable more accurate sentiment classification by domain-specific sentiment lexicons with less sentiment tagging efforts.}
}

@inproceedings{Lu2011automaticconstruction,
  author = {Lu Yue, Castellanos Malu, Dayal Umeshwar and Zhai ChengXiang},
  title = {Automatic Construction of a Context-Aware Sentiment Lexicon: An Optimization Approach},
  year = {2011},
  isbn = {9781450306324},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi-org.tilburguniversity.idm.oclc.org/10.1145/1963405.1963456},
  doi = {10.1145/1963405.1963456},
  abstract = {The explosion of Web opinion data has made essential the need for automatic tools to analyze and understand people's sentiments toward different topics. In most sentiment analysis applications, the sentiment lexicon plays a central role. However, it is well known that there is no universally optimal sentiment lexicon since the polarity of words is sensitive to the topic domain. Even worse, in the same domain the same word may indicate different polarities with respect to different aspects. For example, in a laptop review, "large" is negative for the battery aspect while being positive for the screen aspect. In this paper, we focus on the problem of learning a sentiment lexicon that is not only domain specific but also dependent on the aspect in context given an unlabeled opinionated text collection. We propose a novel optimization framework that provides a unified and principled way to combine different sources of information for learning such a context-dependent sentiment lexicon. Experiments on two data sets (hotel reviews and customer feedback surveys on printers) show that our approach can not only identify new sentiment words specific to the given domain but also determine the different polarities of a word depending on the aspect in context. In further quantitative evaluation, our method is proved to be effective in constructing a high quality lexicon by comparing with a human annotated gold standard. In addition, using the learned context-dependent sentiment lexicon improved the accuracy in an aspect-level sentiment classification task.},
  booktitle = {Proceedings of the 20th International Conference on World Wide Web},
  pages = {347–356},
  numpages = {10},
  keywords = {sentiment analysis, opinion mining, sentiment lexicon, optimization},
  location = {Hyderabad, India},
  series = {WWW '11}
}

@article{ashgar2014DetectionSlang,
  author = {Asghar Muhammad},
  year = {2014},
  month = {05},
  pages = {66-72},
  title = {Detection and Scoring of Internet Slangs for Sentiment Analysis Using SentiWordNet},
  volume = {11},
  journal = {Life Science Journal},
  doi = {10.6084/M9.FIGSHARE.1609621}
}

@article{wang2020automaticconstructiondomainsentiment,
  author = {Wang Yanyan, Yin Fulian, Liu Jianbo and Tosato Marco},
  year = {2020},
  month = {08},
  pages = {},
  title = {Automatic construction of domain sentiment lexicon for semantic disambiguation},
  volume = {79},
  journal = {Multimedia Tools and Applications},
  doi = {10.1007/s11042-020-09030-1}
}

@inproceedings{pei2019slang,
    title = "Slang Detection and Identification",
    author = "Pei Zhengqi, Sun Zhewei and Xu Yang",
    booktitle = "Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/K19-1082",
    doi = "10.18653/v1/K19-1082",
    pages = "881--889",
    abstract = "The prevalence of informal language such as slang presents challenges for natural language systems, particularly in the automatic discovery of flexible word usages. Previous work has explored slang in terms of dictionary construction, sentiment analysis, word formation, and interpretation, but scarce research has attempted the basic problem of slang detection and identification. We examine the extent to which deep learning methods support automatic detection and identification of slang from natural sentences using a combination of bidirectional recurrent neural networks, conditional random field, and multilayer perceptron. We test these models based on a comprehensive set of linguistic features in sentence-level detection and token-level identification of slang. We found that a prominent feature of slang is the surprising use of words across syntactic categories or syntactic shift (e.g., verb-noun). Our best models detect the presence of slang at the sentence level with an F1-score of 0.80 and identify its exact position at the token level with an F1-Score of 0.50.",
}

@article{hochreiter1997lstm,
  author = {Hochreiter Sepp and Schmidhuber Jürgen},
  year = {1997},
  month = {12},
  pages = {1735-80},
  title = {Long Short-term Memory},
  volume = {9},
  journal = {Neural computation},
  doi = {10.1162/neco.1997.9.8.1735}
}

@article{kim2008corpusannotation,
  author = {Kim Jin-Dong, Ohta Tomoko and Tsujii Junichi},
  year = {2008},
  month = {02},
  pages = {10},
  title = {Corpus annotation for mining biomedical events from lterature},
  volume = {9},
  journal = {BMC bioinformatics},
  doi = {10.1186/1471-2105-9-10}
}

@article{arora2009estimationgannotationcost,
  author = {Arora Shilpa, Nyberg Eric and Rose Carolyn},
  year = {2009},
  month = {01},
  pages = {},
  title = {Estimating Annotation Cost for Active Learning in a Multi-Annotator Environment},
  doi = {10.3115/1564131.1564136},
  journal = {HLT-NAACL}
}

@inproceedings{baldridgeosborne2004active,
    title = "Active Learning and the Total Cost of Annotation",
    author = "Baldridge Jason and Osborne Miles",
    booktitle = "Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing",
    month = "jul",
    year = "2004",
    address = "Barcelona, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W04-3202",
    pages = "9-16",
}

@article{miller2020activelearningapproaches, 
  title={Active Learning Approaches for Labeling Text: Review and Assessment of the Performance of Active Learning Approaches}, 
  volume={28}, 
  DOI={10.1017/pan.2020.4}, 
  number={4}, 
  journal={Political Analysis}, 
  publisher={Cambridge University Press}, 
  author={Miller Blake, Linder Fridolin and Mebane Walter R}, 
  year={2020}, 
  pages={532–551}
}

@inproceedings{lewis1994sequential,
  title={A sequential algorithm for training text classifiers},
  author={Lewis David D and Gale William A},
  booktitle={SIGIR94},
  pages={3-12},
  year={1994},
  organization={Springer}
}
