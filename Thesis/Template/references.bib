@book{mackay2003information,
  title={Information theory, inference and learning algorithms},
  author={MacKay, David JC and Mac Kay, David JC},
  year={2003},
  publisher={Cambridge university press}
}

@book{raschka2019pythonmachinelearning,
  title={Python Machine Learning},
  author={Raschka, Sebastian and Mirjalili, Vahid},
  year={2019},
  publisher={Packt Publishing}
}

@article{lyocsa2021yolotrading,
  title={YOLO trading: Riding with the herd during the GameStop episode},
  author={Stefan Lyócsa and Eduard Baumöhl and Tomáš Vyrost},
  journal={Finance Research Letters},
  year={2021}
}

@article{anand2021WallstreetbetsAgainstWallstreet,
  title={WallStreetBets Against Wall Street: The Role of Reddit in the GameStop Short Squeeze},
  author={Abhinav Anand and Jalaj Pathak},
  journal={Indian Institute of Management Bangalore Research Paper Series},
  year={2021}
}

@article{danbolt2015InvestorSentiment,
  title={Investor sentiment and bidder announcement abnormal returns},
  author={Jo Danbolt and Antonios Siganos and Evangelos Vagenas-Nanos},
  journal={Journal of Corporate Finance},
  year={2015},
  pages={164-179}
}

@article{long2021LikeTheStock,
  title={'I Just Like the Stock' versus 'Fear and Loathing on Main Street': The Role of Reddit Sentiment in the GameStop Short Squeeze},
  author={Cheng Long and Brian M. Lucey and Larisa Yarovaya},
  journal={SSRN Electronic Journal},
  year={2021}
}


@article{jemai2021SentimentAnalysis,
  title={Sentiment Analysis Using Machine Learning Algorithms},
  author={Fatma Jemai and Mohamed Hayouni and Sahbi Baccar},
  journal={International Wireless Communications and Mobile Computing},
  year={2021},
  pages={775-779}
}

@article{fu2018lexiconenhancedlstm,
  title={Lexicon Enhanced LSTM With Attention for General Sentiment Analysis},
  author={Fu Xianghua and Yang Jingying and Li Jainqiang and Fang Min and Wang Huihui},
  journal={IEEE Access},
  year={2018},
  pages={71884-71891}
}

@article{das2007yahoo,
  title={Yahoo! for Amazon: Sentiment Extraction from Small Talk on the Web},
  author={Sanjiv R. Das and Mike Y. Chen},
  journal={Management Science},
  year={2007},
  pages={1375-1388}
}

@article{umar2021ataleofcompanyfundamentals,
  title={A tale of company fundamentals vs sentiment driven pricing: The case of GameStop},
  author={Umar Zaghum and Gubareva Mariya and Yousaf Imran and Ali Shoaib},
  journal={Journal of Behavioral and Experimental Finance},
  year={2021}
}

@article{park2015EfficientExtraction,
  title = {Efficient extraction of domain specific sentiment lexicon with active learning},
  journal = {Pattern Recognition Letters},
  volume = {56},
  pages = {38-44},
  year = {2015},
  issn = {0167-8655},
  author = {Sungrae Park and Wonsung Lee and Il-Chul Moon},
  keywords = {Sentiment analysis, Active learning, Sentiment lexicon},
  abstract = {Recent research indicates that a sentiment lexicon focusing on a specific domain leads to better sentiment analyses compared to a general-purpose sentiment lexicon, such as SentiWordNet. In spite of this potential improvement, the cost of building a domain-specific sentiment lexicon hinders its wider and more practical applications. To compensate for this difficulty, we propose extracting a sentiment lexicon from a domain-specific corpus by annotating an intelligently selected subset of documents in the corpus. Specifically, the subset is selected by an active learner with initializations from diverse text analytics, i.e. latent Dirichlet allocation and our proposed lexicon coverage algorithm. This active learning produces a better domain-specific sentiment lexicon which results in a higher accuracy of the sentiment classification. Subsequently, we evaluate extracted sentiment lexicons by observing (1) the increased F1 measure in sentiment classifications and (2) the increased similarity to the sentiment lexicon with the full annotation. We expect that this contribution will enable more accurate sentiment classification by domain-specific sentiment lexicons with less sentiment tagging efforts.}
}

@inproceedings{Lu2011automaticconstruction,
  author = {Lu Yue and Castellanos Malu and Dayal Umeshwar and Zhai ChengXiang},
  title = {Automatic Construction of a Context-Aware Sentiment Lexicon: An Optimization Approach},
  year = {2011},
  isbn = {9781450306324},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi-org.tilburguniversity.idm.oclc.org/10.1145/1963405.1963456},
  doi = {10.1145/1963405.1963456},
  abstract = {The explosion of Web opinion data has made essential the need for automatic tools to analyze and understand people's sentiments toward different topics. In most sentiment analysis applications, the sentiment lexicon plays a central role. However, it is well known that there is no universally optimal sentiment lexicon since the polarity of words is sensitive to the topic domain. Even worse, in the same domain the same word may indicate different polarities with respect to different aspects. For example, in a laptop review, "large" is negative for the battery aspect while being positive for the screen aspect. In this paper, we focus on the problem of learning a sentiment lexicon that is not only domain specific but also dependent on the aspect in context given an unlabeled opinionated text collection. We propose a novel optimization framework that provides a unified and principled way to combine different sources of information for learning such a context-dependent sentiment lexicon. Experiments on two data sets (hotel reviews and customer feedback surveys on printers) show that our approach can not only identify new sentiment words specific to the given domain but also determine the different polarities of a word depending on the aspect in context. In further quantitative evaluation, our method is proved to be effective in constructing a high quality lexicon by comparing with a human annotated gold standard. In addition, using the learned context-dependent sentiment lexicon improved the accuracy in an aspect-level sentiment classification task.},
  booktitle = {Proceedings of the 20th International Conference on World Wide Web},
  pages = {347–356},
  numpages = {10},
  keywords = {sentiment analysis, opinion mining, sentiment lexicon, optimization},
  location = {Hyderabad, India},
  series = {WWW '11}
}

@article{ashgar2014DetectionSlang,
  author = {Asghar Muhammad},
  year = {2014},
  month = {05},
  pages = {66-72},
  title = {Detection and Scoring of Internet Slangs for Sentiment Analysis Using SentiWordNet},
  volume = {11},
  journal = {Life Science Journal},
  doi = {10.6084/M9.FIGSHARE.1609621}
}

@article{wang2020automaticconstructiondomainsentiment,
  author = {Wang Yanyan and Yin Fulian and Liu Jianbo and Tosato Marco},
  year = {2020},
  month = {08},
  pages = {},
  title = {Automatic construction of domain sentiment lexicon for semantic disambiguation},
  volume = {79},
  journal = {Multimedia Tools and Applications},
  doi = {10.1007/s11042-020-09030-1}
}

@inproceedings{pei2019slang,
    title = "Slang Detection and Identification",
    author = "Pei Zhengqi and Sun Zhewei and Xu Yang",
    booktitle = "Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/K19-1082",
    doi = "10.18653/v1/K19-1082",
    pages = "881--889",
    abstract = "The prevalence of informal language such as slang presents challenges for natural language systems, particularly in the automatic discovery of flexible word usages. Previous work has explored slang in terms of dictionary construction, sentiment analysis, word formation, and interpretation, but scarce research has attempted the basic problem of slang detection and identification. We examine the extent to which deep learning methods support automatic detection and identification of slang from natural sentences using a combination of bidirectional recurrent neural networks, conditional random field, and multilayer perceptron. We test these models based on a comprehensive set of linguistic features in sentence-level detection and token-level identification of slang. We found that a prominent feature of slang is the surprising use of words across syntactic categories or syntactic shift (e.g., verb-noun). Our best models detect the presence of slang at the sentence level with an F1-score of 0.80 and identify its exact position at the token level with an F1-Score of 0.50.",
}

@article{hochreiter1997lstm,
  author = {Sepp Hochreiter and Jürgen Schmidhuber},
  year = {1997},
  month = {12},
  pages = {1735-80},
  title = {Long Short-term Memory},
  volume = {9},
  journal = {Neural computation},
  doi = {10.1162/neco.1997.9.8.1735}
}

@article{kim2008corpusannotation,
  author = {Kim Jin-Dong and Ohta Tomoko and Tsujii Junichi},
  year = {2008},
  month = {02},
  pages = {10},
  title = {Corpus annotation for mining biomedical events from lterature},
  volume = {9},
  journal = {BMC bioinformatics},
  doi = {10.1186/1471-2105-9-10}
}

@article{arora2009estimationgannotationcost,
  author = {Shilpa Arora and Eric Nyberg and Carolyn Rose},
  year = {2009},
  month = {01},
  pages = {},
  title = {Estimating Annotation Cost for Active Learning in a Multi-Annotator Environment},
  doi = {10.3115/1564131.1564136},
  journal = {HLT-NAACL}
}

@inproceedings{baldridgeosborne2004active,
    title = "Active Learning and the Total Cost of Annotation",
    author = "Jason Baldridge and Miles Osborne",
    booktitle = "Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing",
    month = "jul",
    year = "2004",
    address = "Barcelona, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W04-3202",
    pages = "9-16",
}

@article{miller2020activelearningapproaches, 
  title={Active Learning Approaches for Labeling Text: Review and Assessment of the Performance of Active Learning Approaches}, 
  volume={28}, 
  DOI={10.1017/pan.2020.4}, 
  number={4}, 
  journal={Political Analysis}, 
  publisher={Cambridge University Press}, 
  author={Blake Miller and Fridolin Linder and Walter R Mebane}, 
  year={2020}, 
  pages={532–551}
}

@inproceedings{lewis1994sequential,
  title={A sequential algorithm for training text classifiers},
  author={David D Lewisand William A Gale},
  booktitle={SIGIR94},
  pages={3-12},
  year={1994},
  organization={Springer}
}

@inproceedings{parveen2016sentimentanalysistwitter,
  author = {Huma Parveen and Shikha Pandey},
  year = {2016},
  month = {01},
  pages = {416-419},
  title = {Sentiment analysis on Twitter Data-set using Naive Bayes algorithm},
  doi = {10.1109/ICATCCT.2016.7912034}
}


@article{sazzed2021ssentia,
  title = {SSentiA: A Self-supervised Sentiment Analyzer for classification from unlabeled data},
  journal = {Machine Learning with Applications},
  volume = {4},
  pages = {100026},
  year = {2021},
  issn = {2666-8270},
  doi = {https://doi.org/10.1016/j.mlwa.2021.100026},
  url = {https://www.sciencedirect.com/science/article/pii/S2666827021000074},
  author = {Salim Sazzed and Sampath Jayarathna},
  abstract = {In recent years, supervised machine learning (ML) methods have realized remarkable performance gains for sentiment classification utilizing labeled data. However, labeled data are usually expensive to obtain, thus, not always achievable. When annotated data are unavailable, the unsupervised tools are exercised, which still lag behind the performance of supervised ML methods by a large margin. Therefore, in this work, we focus on improving the performance of sentiment classification from unlabeled data. We present a self-supervised hybrid methodology SSentiA (Self-supervised Sentiment Analyzer) that couples an ML classifier with a lexicon-based method for sentiment classification from unlabeled data. We first introduce LRSentiA (Lexical Rule-based Sentiment Analyzer), a lexicon-based method to predict the semantic orientation of a review along with the confidence score of prediction. Utilizing the confidence scores of LRSentiA, we generate highly accurate pseudo-labels for SSentiA that incorporates a supervised ML algorithm to improve the performance of sentiment classification for less polarized and complex reviews. We compare the performances of LRSentiA and SSSentA with the existing unsupervised, lexicon-based and self-supervised methods in multiple datasets. The LRSentiA performs similarly to the existing lexicon-based methods in both binary and 3-class sentiment analysis. By combining LRSentiA with an ML classifier, the hybrid approach SSentiA attains 10%–30% improvements in macro F1 score for both binary and 3-class sentiment analysis. The results suggest that in domains where annotated data are unavailable, SSentiA can significantly improve the performance of sentiment classification. Moreover, we demonstrate that using 30%–60% annotated training data, SSentiA delivers similar performances of the fully labeled training dataset.}
}

@article{jung2019automatedclassification,
  author = {Jung Namcheol and Lee Ghang},
  year = {2019},
  month = {04},
  pages = {},
  title = {Automated classification of building information modeling (BIM) case studies by BIM use based on natural language processing (NLP) and unsupervised learning},
  volume = {41},
  journal = {Advanced Engineering Informatics},
  doi = {10.1016/j.aei.2019.04.007}
}

@article{binu2020dimreductiontsne,
  title = {Dimensionality reduction and visualisation of hyperspectral ink data using t-SNE},
  journal = {Forensic Science International},
  volume = {311},
  pages = {110194},
  year = {2020},
  issn = {0379-0738},
  doi = {https://doi.org/10.1016/j.forsciint.2020.110194},
  url = {https://www.sciencedirect.com/science/article/pii/S0379073820300566},
  author = {{Melit Devassy} Binu and George Sony},
  keywords = {Dimensionality reduction, Hyperspectral imaging, Ink analysis, t-SNE, Visualisation},
  abstract = {Ink analysis is an important tool in forensic science and document analysis. Hyperspectral imaging (HSI) captures large number of narrowband images across the electromagnetic spectrum. HSI is one of the non-invasive tools used in forensic document analysis, especially for ink analysis. The substantial information from multiple bands in HSI images empowers us to make non-destructive diagnosis and identification of forensic evidence in questioned documents. The presence of numerous band information in HSI data makes processing and storing becomes a computationally challenging task. Therefore, dimensionality reduction and visualization play a vital role in HSI data processing to achieve efficient processing and effortless understanding of the data. In this paper, an advanced approach known as t-Distributed Stochastic Neighbor embedding (t-SNE) algorithm is introduced into the ink analysis problem. t-SNE extracts the non-linear similarity features between spectra to scale them into a lower dimension. This capability of the t-SNE algorithm for ink spectral data is verified visually and quantitatively, the two-dimensional data generated by the t-SNE showed a better visualization and a greater improvement in clustering quality in comparison with Principal Component Analysis (PCA).}
}

@article{tomasev2014roleofhubness,
  author={Nenad Tomasev and Milos Radovanovic and Dunja Mladenic and Mirjana Ivanovic},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  title={The Role of Hubness in Clustering High-Dimensional Data},
  year={2014},
  volume={26},
  number={3},
  pages={739-751},
  doi={10.1109/TKDE.2013.25}
}

@inproceedings{kang2004usingclusterbasedsampling,
  title={Using Cluster-Based Sampling to Select Initial Training Set for Active Learning in Text Classification},
  author={Jaeho Kang and Kwang Ryel Ryu and {Hyuk-chul} Kwon},
  booktitle={PAKDD},
  year={2004}
}

@inproceedings{settles2009activeLL,
  title={Active Learning Literature Survey},
  author={Burr Settles},
  year={2009}
}

@booklet{rayan2019sentimentanalysisemail,
  author = {Rayan Salah and Neamat El Gayar},
  title = {Sentiment Analysis using Unlabeled Email data},
  howpublished = {EasyChair Preprint no. 2080},
  year = {2019}
}

@misc{lu2019investigating,
      title={Investigating the Effectiveness of Representations Based on Word-Embeddings in Active Learning for Labelling Text Datasets}, 
      author={Jinghui Lu and Maeve Henchion and Brian Mac Namee},
      year={2019},
      eprint={1910.03505},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{danka2018modal,
      title={modAL: A modular active learning framework for Python}, 
      author={Tivadar Danka and Peter Horvath},
      year={2018},
      eprint={1805.00979},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{alves2014comparisonsvm,
  author = {{Alves Andr\'{e} Luiz} Firmino and {Cl\'{a}udio de Souza} Baptista and {Anderson Almeida} Firmino and {Maxwell Guimar\~{a}es de} Oliveira and {Anselmo Cardoso de} Paiva},
  title = {A Comparison of SVM Versus Naive-Bayes Techniques for Sentiment Analysis in Tweets: A Case Study with the 2013 FIFA Confederations Cup}, 
  year = {2014},
  isbn = {9781450332309},
  publisher = {Association for Computing Machinery}, 
  address = {New York, NY, USA}, 
  url = {https://doi-org.tilburguniversity.idm.oclc.org/10.1145/2664551.2664561}, 
  doi = {10.1145/2664551.2664561}, 
  booktitle = {Proceedings of the 20th Brazilian Symposium on Multimedia and the Web}, 
  pages = {123–130}, 
  numpages = {8}, 
  keywords = {analysis of sentiment, natural language processing (nlp), support vector machine (svm), naive- bayes}
}

@inproceedings{osbonre2004ensemblebased,
  author = {Miles Osborne and Jason Baldridge},
  year = {2004},
  month = {01},
  pages = {89-96},
  title = {Ensemblebased Active Learning for Parse Selection.}
}

@article{song2017novelclassification,
  author = {Junseok Song and {Kyung Tae} Kim and Byungjun Lee and Sangyoung Kim and Hee Yong Youn},
  title = {A novel classification approach based on Naïve Bayes for Twitter sentiment analysis},
  journal={KSII TRANSACTIONS ON INTERNET AND INFORMATION SYSTEMS},
  year = {2017},
  pages = {2996-3011}
}

@article{priyantina2019sentimentanalysishotel,
  author = {Reza Priyantina and Riyanarto Sarno},
  year = {2019},
  month = {06},
  pages = {142-155},
  title = {Sentiment Analysis of Hotel Reviews Using Latent Dirichlet Allocation, Semantic Similarity and LSTM},
  volume = {12},
  journal = {International Journal of Intelligent Engineering and Systems},
  doi = {10.22266/ijies2019.0831.14}
}

@inproceedings{devlin2019bertpo,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
  booktitle={NAACL},
  year={2019}
}

@misc{googlegithub,
  url = {https://github.com/google-research/bert},
  year = {2020},
  month = {March},
  day = {11},
  author = {{Google Research}},
  title = {bert}
}

@misc{diangson2021betonreddit,
  author = {Bryan Diangson and Nicholas Jung},
  title = {Bet it on Reddit: The Effects of Reddit Chatter on Highly Shorted Stocks},
  year = {2021}
}

@misc{semenova2021reddits,
      title={Reddit's self-organised bull runs: Social contagion and asset prices}, 
      author={Valentina Semenova and Julian Winkler},
      year={2021},
      eprint={2104.01847},
      archivePrefix={arXiv},
      primaryClass={econ.GN}
}

@misc{elastic2015,
  author       = {Alex Brasetvik},
  howpublished = {Web},
  title        = {Uses of Elasticsearch, and Things to Learn},
  year         = {2015},
  month        = {February},
  day          = {15},
  url          = {https://www.elastic.co/blog/found-uses-of-elasticsearch}
}

@misc{pmaw2021,
  author       = {Matthew Podolak},
  howpublished = {Web},
  title        = {PMAW: Pushshift Multithread API Wrapper},
  year         = {2021},
  month        = {October},
  day          = {1},
  url          = {https://github.com/mattpodolak/pmaw}
}