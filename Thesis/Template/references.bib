@book{mackay2003information,
  title={Information theory, inference and learning algorithms},
  author={MacKay, David JC and Mac Kay, David JC},
  year={2003},
  publisher={Cambridge university press}
}

@book{raschka2019pythonmachinelearning,
  title={Python Machine Learning},
  author={Raschka, Sebastian and Mirjalili, Vahid},
  year={2019},
  publisher={Packt Publishing}
}

@article{lyocsa2021yolotrading,
  title={YOLO trading: Riding with the herd during the GameStop episode},
  author={Stefan Lyócsa and Eduard Baumöhl and Tomáš Vyrost},
  journal={Finance Research Letters},
  year={2021}
}

@article{anand2021WallstreetbetsAgainstWallstreet,
  title={WallStreetBets Against Wall Street: The Role of Reddit in the GameStop Short Squeeze},
  author={Abhinav Anand and Jalaj Pathak},
  journal={Indian Institute of Management Bangalore Research Paper Series},
  year={2021}
}

@article{danbolt2015InvestorSentiment,
  title={Investor sentiment and bidder announcement abnormal returns},
  author={Jo Danbolt and Antonios Siganos and Evangelos Vagenas-Nanos},
  journal={Journal of Corporate Finance},
  year={2015},
  pages={164-179}
}

@article{long2021LikeTheStock,
  title={'I Just Like the Stock' versus 'Fear and Loathing on Main Street': The Role of Reddit Sentiment in the GameStop Short Squeeze},
  author={Cheng Long and Brian M. Lucey and Larisa Yarovaya},
  journal={SSRN Electronic Journal},
  year={2021}
}


@article{jemai2021SentimentAnalysis,
  title={Sentiment Analysis Using Machine Learning Algorithms},
  author={Fatma Jemai and Mohamed Hayouni and Sahbi Baccar},
  journal={International Wireless Communications and Mobile Computing},
  year={2021},
  pages={775-779}
}

@article{fu2018lexiconenhancedlstm,
  title={Lexicon Enhanced LSTM With Attention for General Sentiment Analysis},
  author={Fu Xianghua and Yang Jingying and Li Jainqiang and Fang Min and Wang Huihui},
  journal={IEEE Access},
  year={2018},
  pages={71884-71891}
}

@article{das2007yahoo,
  title={Yahoo! for Amazon: Sentiment Extraction from Small Talk on the Web},
  author={Sanjiv R. Das and Mike Y. Chen},
  journal={Management Science},
  year={2007},
  pages={1375-1388}
}

@article{umar2021ataleofcompanyfundamentals,
  title={A tale of company fundamentals vs sentiment driven pricing: The case of GameStop},
  author={Umar Zaghum and Gubareva Mariya and Yousaf Imran and Ali Shoaib},
  journal={Journal of Behavioral and Experimental Finance},
  year={2021}
}

@article{park2015EfficientExtraction,
  title = {Efficient extraction of domain specific sentiment lexicon with active learning},
  journal = {Pattern Recognition Letters},
  volume = {56},
  pages = {38-44},
  year = {2015},
  issn = {0167-8655},
  author = {Sungrae Park and Wonsung Lee and Il-Chul Moon},
  keywords = {Sentiment analysis, Active learning, Sentiment lexicon},
  abstract = {Recent research indicates that a sentiment lexicon focusing on a specific domain leads to better sentiment analyses compared to a general-purpose sentiment lexicon, such as SentiWordNet. In spite of this potential improvement, the cost of building a domain-specific sentiment lexicon hinders its wider and more practical applications. To compensate for this difficulty, we propose extracting a sentiment lexicon from a domain-specific corpus by annotating an intelligently selected subset of documents in the corpus. Specifically, the subset is selected by an active learner with initializations from diverse text analytics, i.e. latent Dirichlet allocation and our proposed lexicon coverage algorithm. This active learning produces a better domain-specific sentiment lexicon which results in a higher accuracy of the sentiment classification. Subsequently, we evaluate extracted sentiment lexicons by observing (1) the increased F1 measure in sentiment classifications and (2) the increased similarity to the sentiment lexicon with the full annotation. We expect that this contribution will enable more accurate sentiment classification by domain-specific sentiment lexicons with less sentiment tagging efforts.}
}

@inproceedings{Lu2011automaticconstruction,
  author = {Lu Yue and Castellanos Malu and Dayal Umeshwar and Zhai ChengXiang},
  title = {Automatic Construction of a Context-Aware Sentiment Lexicon: An Optimization Approach},
  year = {2011},
  isbn = {9781450306324},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi-org.tilburguniversity.idm.oclc.org/10.1145/1963405.1963456},
  doi = {10.1145/1963405.1963456},
  abstract = {The explosion of Web opinion data has made essential the need for automatic tools to analyze and understand people's sentiments toward different topics. In most sentiment analysis applications, the sentiment lexicon plays a central role. However, it is well known that there is no universally optimal sentiment lexicon since the polarity of words is sensitive to the topic domain. Even worse, in the same domain the same word may indicate different polarities with respect to different aspects. For example, in a laptop review, "large" is negative for the battery aspect while being positive for the screen aspect. In this paper, we focus on the problem of learning a sentiment lexicon that is not only domain specific but also dependent on the aspect in context given an unlabeled opinionated text collection. We propose a novel optimization framework that provides a unified and principled way to combine different sources of information for learning such a context-dependent sentiment lexicon. Experiments on two data sets (hotel reviews and customer feedback surveys on printers) show that our approach can not only identify new sentiment words specific to the given domain but also determine the different polarities of a word depending on the aspect in context. In further quantitative evaluation, our method is proved to be effective in constructing a high quality lexicon by comparing with a human annotated gold standard. In addition, using the learned context-dependent sentiment lexicon improved the accuracy in an aspect-level sentiment classification task.},
  booktitle = {Proceedings of the 20th International Conference on World Wide Web},
  pages = {347-356},
  numpages = {10},
  keywords = {sentiment analysis, opinion mining, sentiment lexicon, optimization},
  location = {Hyderabad, India},
  series = {WWW '11}
}

@article{ashgar2014DetectionSlang,
  author = {Asghar Muhammad},
  year = {2014},
  month = {05},
  pages = {66-72},
  title = {Detection and Scoring of Internet Slangs for Sentiment Analysis Using SentiWordNet},
  volume = {11},
  journal = {Life Science Journal},
  doi = {10.6084/M9.FIGSHARE.1609621}
}

@article{wang2020automaticconstructiondomainsentiment,
  author = {Wang Yanyan and Yin Fulian and Liu Jianbo and Tosato Marco},
  year = {2020},
  month = {08},
  pages = {},
  title = {Automatic construction of domain sentiment lexicon for semantic disambiguation},
  volume = {79},
  journal = {Multimedia Tools and Applications},
  doi = {10.1007/s11042-020-09030-1}
}

@inproceedings{pei2019slang,
    title = "Slang Detection and Identification",
    author = "Pei Zhengqi and Sun Zhewei and Xu Yang",
    booktitle = "Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/K19-1082",
    doi = "10.18653/v1/K19-1082",
    pages = "881--889",
    abstract = "The prevalence of informal language such as slang presents challenges for natural language systems, particularly in the automatic discovery of flexible word usages. Previous work has explored slang in terms of dictionary construction, sentiment analysis, word formation, and interpretation, but scarce research has attempted the basic problem of slang detection and identification. We examine the extent to which deep learning methods support automatic detection and identification of slang from natural sentences using a combination of bidirectional recurrent neural networks, conditional random field, and multilayer perceptron. We test these models based on a comprehensive set of linguistic features in sentence-level detection and token-level identification of slang. We found that a prominent feature of slang is the surprising use of words across syntactic categories or syntactic shift (e.g., verb-noun). Our best models detect the presence of slang at the sentence level with an F1-score of 0.80 and identify its exact position at the token level with an F1-Score of 0.50.",
}

@article{hochreiter1997lstm,
  author = {Sepp Hochreiter and Jürgen Schmidhuber},
  year = {1997},
  month = {12},
  pages = {1735-80},
  title = {Long Short-term Memory},
  volume = {9},
  journal = {Neural computation},
  doi = {10.1162/neco.1997.9.8.1735}
}

@article{kim2008corpusannotation,
  author = {Kim Jin-Dong and Ohta Tomoko and Tsujii Junichi},
  year = {2008},
  month = {02},
  pages = {10},
  title = {Corpus annotation for mining biomedical events from lterature},
  volume = {9},
  journal = {BMC bioinformatics},
  doi = {10.1186/1471-2105-9-10}
}

@article{arora2009estimationgannotationcost,
  author = {Shilpa Arora and Eric Nyberg and Carolyn Rose},
  year = {2009},
  month = {01},
  pages = {},
  title = {Estimating Annotation Cost for Active Learning in a Multi-Annotator Environment},
  doi = {10.3115/1564131.1564136},
  journal = {HLT-NAACL}
}

@inproceedings{baldridgeosborne2004active,
    title = "Active Learning and the Total Cost of Annotation",
    author = "Jason Baldridge and Miles Osborne",
    booktitle = "Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing",
    month = "jul",
    year = "2004",
    address = "Barcelona, Spain",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W04-3202",
    pages = "9-16",
}

@article{miller2020activelearningapproaches, 
  title={Active Learning Approaches for Labeling Text: Review and Assessment of the Performance of Active Learning Approaches}, 
  volume={28}, 
  DOI={10.1017/pan.2020.4}, 
  number={4}, 
  journal={Political Analysis}, 
  publisher={Cambridge University Press}, 
  author={Blake Miller and Fridolin Linder and Walter R Mebane}, 
  year={2020}, 
  pages={532–551}
}

@inproceedings{lewis1994sequential,
  title={A sequential algorithm for training text classifiers},
  author={David D Lewisand William A Gale},
  booktitle={SIGIR94},
  pages={3-12},
  year={1994},
  organization={Springer}
}

@inproceedings{parveen2016sentimentanalysistwitter,
  author = {Huma Parveen and Shikha Pandey},
  year = {2016},
  month = {01},
  pages = {416-419},
  title = {Sentiment analysis on Twitter Data-set using Naive Bayes algorithm},
  doi = {10.1109/ICATCCT.2016.7912034}
}


@article{sazzed2021ssentia,
  title = {SSentiA: A Self-supervised Sentiment Analyzer for classification from unlabeled data},
  journal = {Machine Learning with Applications},
  volume = {4},
  pages = {100026},
  year = {2021},
  issn = {2666-8270},
  doi = {https://doi.org/10.1016/j.mlwa.2021.100026},
  url = {https://www.sciencedirect.com/science/article/pii/S2666827021000074},
  author = {Salim Sazzed and Sampath Jayarathna},
  abstract = {In recent years, supervised machine learning (ML) methods have realized remarkable performance gains for sentiment classification utilizing labeled data. However, labeled data are usually expensive to obtain, thus, not always achievable. When annotated data are unavailable, the unsupervised tools are exercised, which still lag behind the performance of supervised ML methods by a large margin. Therefore, in this work, we focus on improving the performance of sentiment classification from unlabeled data. We present a self-supervised hybrid methodology SSentiA (Self-supervised Sentiment Analyzer) that couples an ML classifier with a lexicon-based method for sentiment classification from unlabeled data. We first introduce LRSentiA (Lexical Rule-based Sentiment Analyzer), a lexicon-based method to predict the semantic orientation of a review along with the confidence score of prediction. Utilizing the confidence scores of LRSentiA, we generate highly accurate pseudo-labels for SSentiA that incorporates a supervised ML algorithm to improve the performance of sentiment classification for less polarized and complex reviews. We compare the performances of LRSentiA and SSSentA with the existing unsupervised, lexicon-based and self-supervised methods in multiple datasets. The LRSentiA performs similarly to the existing lexicon-based methods in both binary and 3-class sentiment analysis. By combining LRSentiA with an ML classifier, the hybrid approach SSentiA attains 10%–30% improvements in macro F1 score for both binary and 3-class sentiment analysis. The results suggest that in domains where annotated data are unavailable, SSentiA can significantly improve the performance of sentiment classification. Moreover, we demonstrate that using 30%–60% annotated training data, SSentiA delivers similar performances of the fully labeled training dataset.}
}

@article{jung2019automatedclassification,
  author = {Jung Namcheol and Lee Ghang},
  year = {2019},
  month = {04},
  pages = {},
  title = {Automated classification of building information modeling (BIM) case studies by BIM use based on natural language processing (NLP) and unsupervised learning},
  volume = {41},
  journal = {Advanced Engineering Informatics},
  doi = {10.1016/j.aei.2019.04.007}
}

@article{binu2020dimreductiontsne,
  title = {Dimensionality reduction and visualisation of hyperspectral ink data using t-SNE},
  journal = {Forensic Science International},
  volume = {311},
  pages = {110194},
  year = {2020},
  issn = {0379-0738},
  doi = {https://doi.org/10.1016/j.forsciint.2020.110194},
  url = {https://www.sciencedirect.com/science/article/pii/S0379073820300566},
  author = {{Melit Devassy} Binu and George Sony},
  keywords = {Dimensionality reduction, Hyperspectral imaging, Ink analysis, t-SNE, Visualisation},
  abstract = {Ink analysis is an important tool in forensic science and document analysis. Hyperspectral imaging (HSI) captures large number of narrowband images across the electromagnetic spectrum. HSI is one of the non-invasive tools used in forensic document analysis, especially for ink analysis. The substantial information from multiple bands in HSI images empowers us to make non-destructive diagnosis and identification of forensic evidence in questioned documents. The presence of numerous band information in HSI data makes processing and storing becomes a computationally challenging task. Therefore, dimensionality reduction and visualization play a vital role in HSI data processing to achieve efficient processing and effortless understanding of the data. In this paper, an advanced approach known as t-Distributed Stochastic Neighbor embedding (t-SNE) algorithm is introduced into the ink analysis problem. t-SNE extracts the non-linear similarity features between spectra to scale them into a lower dimension. This capability of the t-SNE algorithm for ink spectral data is verified visually and quantitatively, the two-dimensional data generated by the t-SNE showed a better visualization and a greater improvement in clustering quality in comparison with Principal Component Analysis (PCA).}
}

@article{tomasev2014roleofhubness,
  author={Nenad Tomasev and Milos Radovanovic and Dunja Mladenic and Mirjana Ivanovic},
  journal={IEEE Transactions on Knowledge and Data Engineering},
  title={The Role of Hubness in Clustering High-Dimensional Data},
  year={2014},
  volume={26},
  number={3},
  pages={739-751},
  doi={10.1109/TKDE.2013.25}
}

@inproceedings{kang2004usingclusterbasedsampling,
  title={Using Cluster-Based Sampling to Select Initial Training Set for Active Learning in Text Classification},
  author={Jaeho Kang and Kwang Ryel Ryu and {Hyuk-chul} Kwon},
  booktitle={PAKDD},
  year={2004}
}

@inproceedings{settles2009activeLL,
  title={Active Learning Literature Survey},
  author={Burr Settles},
  year={2009}
}

@booklet{rayan2019sentimentanalysisemail,
  author = {Rayan Salah and Neamat El Gayar},
  title = {Sentiment Analysis using Unlabeled Email data},
  howpublished = {EasyChair Preprint no. 2080},
  year = {2019}
}

@misc{lu2019investigating,
      title={Investigating the Effectiveness of Representations Based on Word-Embeddings in Active Learning for Labelling Text Datasets}, 
      author={Jinghui Lu and Maeve Henchion and Brian Mac Namee},
      year={2019},
      eprint={1910.03505},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}

@misc{danka2018modal,
      title={modAL: A modular active learning framework for Python}, 
      author={Tivadar Danka and Peter Horvath},
      year={2018},
      eprint={1805.00979},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@inproceedings{alves2014comparisonsvm,
  author = {{Alves Andr\'{e} Luiz} Firmino and {Cl\'{a}udio de Souza} Baptista and {Anderson Almeida} Firmino and {Maxwell Guimar\~{a}es de} Oliveira and {Anselmo Cardoso de} Paiva},
  title = {A Comparison of SVM Versus Naive-Bayes Techniques for Sentiment Analysis in Tweets: A Case Study with the 2013 FIFA Confederations Cup}, 
  year = {2014},
  isbn = {9781450332309},
  publisher = {Association for Computing Machinery}, 
  address = {New York, NY, USA}, 
  url = {https://doi-org.tilburguniversity.idm.oclc.org/10.1145/2664551.2664561}, 
  doi = {10.1145/2664551.2664561}, 
  booktitle = {Proceedings of the 20th Brazilian Symposium on Multimedia and the Web}, 
  pages = {123–130}, 
  numpages = {8}, 
  keywords = {analysis of sentiment, natural language processing (nlp), support vector machine (svm), naive- bayes}
}

@inproceedings{osbonre2004ensemblebased,
  author = {Miles Osborne and Jason Baldridge},
  year = {2004},
  month = {01},
  pages = {89-96},
  title = {Ensemblebased Active Learning for Parse Selection.}
}

@article{song2017novelclassification,
  author = {Junseok Song and {Kyung Tae} Kim and Byungjun Lee and Sangyoung Kim and Hee Yong Youn},
  title = {A novel classification approach based on Naïve Bayes for Twitter sentiment analysis},
  journal={KSII TRANSACTIONS ON INTERNET AND INFORMATION SYSTEMS},
  year = {2017},
  pages = {2996-3011}
}

@article{priyantina2019sentimentanalysishotel,
  author = {Reza Priyantina and Riyanarto Sarno},
  year = {2019},
  month = {06},
  pages = {142-155},
  title = {Sentiment Analysis of Hotel Reviews Using Latent Dirichlet Allocation, Semantic Similarity and LSTM},
  volume = {12},
  journal = {International Journal of Intelligent Engineering and Systems},
  doi = {10.22266/ijies2019.0831.14}
}

@misc{googlegithub,
  url = {https://github.com/google-research/bert},
  year = {2020},
  month = {March},
  day = {11},
  author = {{Google Research}},
  title = {bert}
}

@misc{diangson2021betonreddit,
  author = {Bryan Diangson and Nicholas Jung},
  title = {Bet it on Reddit: The Effects of Reddit Chatter on Highly Shorted Stocks},
  year = {2021}
}

@misc{semenova2021reddits,
      title={Reddit's self-organised bull runs: Social contagion and asset prices}, 
      author={Valentina Semenova and Julian Winkler},
      year={2021},
      eprint={2104.01847},
      archivePrefix={arXiv},
      primaryClass={econ.GN}
}

@misc{elastic2015,
  author       = {Alex Brasetvik},
  howpublished = {Web},
  title        = {Uses of Elasticsearch, and Things to Learn},
  year         = {2015},
  month        = {February},
  day          = {15},
  url          = {https://www.elastic.co/blog/found-uses-of-elasticsearch}
}

@misc{pmaw2021,
  author       = {Matthew Podolak},
  howpublished = {Web},
  title        = {PMAW: Pushshift Multithread API Wrapper},
  year         = {2021},
  month        = {October},
  day          = {1},
  url          = {https://github.com/mattpodolak/pmaw}
}

@misc{camachocollados2018role,
  title={On the Role of Text Preprocessing in Neural Network Architectures: An Evaluation Study on Text Categorization and Sentiment Analysis}, 
  author={Jose Camacho-Collados and Mohammad Taher Pilehvar},
  year={2018},
  eprint={1707.01780},
  archivePrefix={arXiv},
  primaryClass={cs.CL}
}

@article{zhao2017comparisontextprocess,
  author = {Jianqiang Zhao and Xiaolin Gui},
  year = {2017},
  month = {02},
  pages = {1-1},
  title = {Comparison Research on Text Pre-processing Methods on Twitter Sentiment Analysis},
  volume = {PP},
  journal = {IEEE Access},
  doi = {10.1109/ACCESS.2017.2672677}
}


@InProceedings{vanishinggradients2020pmlr,
  title = 	 {Beyond exploding and vanishing gradients: analysing RNN training using attractors and smoothness},
  author =       {Antonio H. Ribeiro and Koen Tiels and Luis A. Aguirre and Thomas Schön},
  booktitle = 	 {Proceedings of the Twenty Third International Conference on Artificial Intelligence and Statistics},
  pages = 	 {2370--2380},
  year = 	 {2020},
  editor = 	 {Chiappa, Silvia and Calandra, Roberto},
  volume = 	 {108},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {26--28 Aug},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v108/ribeiro20a/ribeiro20a.pdf},
  url = 	 {https://proceedings.mlr.press/v108/ribeiro20a.html},
  abstract = 	 {The exploding and vanishing gradient problem has been the major conceptual principle behind most architecture and training improvements in recurrent neural networks (RNNs) during the last decade.  In this paper, we argue that this principle, while powerful, might need some refinement to explain recent developments. We refine the concept of exploding gradients by reformulating the problem in terms of the cost function smoothness, which gives insight into higher-order derivatives and the existence of regions with many close local minima. We also clarify the distinction between vanishing gradients and the need for the RNN to learn attractors to fully use its expressive power. Through the lens of these refinements, we shed new light on recent developments in the RNN field, namely stable RNN and unitary (or orthogonal) RNNs.}
}

@misc{talamas2021socialmediaeffectsonthemarket,
  author = {Juan Talamás},
  year = {2021},
  month = {05},
  pages = {},
  title = {Social media Effects on the market: Reddit Data analysis on Stocks},
  doi = {10.13140/RG.2.2.24180.88960}
}

@INPROCEEDINGS{xiao2018word2veclstm,
  author={Lizhong Xiao and Guangzhong Wang and Yang Zuo},
  booktitle={2018 11th International Symposium on Computational Intelligence and Design (ISCID)},
  title={Research on Patent Text Classification Based on Word2Vec and LSTM},
  year={2018},
  volume={01},
  pages={71-74},
  doi={10.1109/ISCID.2018.00023}
}

@INPROCEEDINGS{deng2009transferlearning,
  author={Jia Deng and Wei Dong and Richard Socher and Li-Jia Li and Li Kai and Fei-Fei Li},
  booktitle={2009 IEEE Conference on Computer Vision and Pattern Recognition},
  title={ImageNet: A large-scale hierarchical image database},
  year={2009},
  volume={},
  number={},
  pages={248-255},
  doi={10.1109/CVPR.2009.5206848}
}

@misc{devlin2019bert,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}, 
  author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
  year={2019},
  eprint={1810.04805},
  archivePrefix={arXiv},
  primaryClass={cs.CL}
}

@inproceedings{Du2020AdversarialAD,
  title={Adversarial and Domain-Aware BERT for Cross-Domain Sentiment Analysis},
  author={Chunning Du and Haifeng Sun and Jingyu Wang and Q. Qi and Jianxin Liao},
  booktitle={ACL},
  year={2020}
}

@misc{kotelnikova2021lexiconbased,
  title={Lexicon-based Methods vs. BERT for Text Sentiment Analysis}, 
  author={Anastasia Kotelnikova and Danil Paschenko and Klavdiya Bochenina and Evgeny Kotelnikov},
  year={2021},
  eprint={2111.10097},
  archivePrefix={arXiv},
  primaryClass={cs.CL}
}

@misc{abbas2019mnb,
  author = {Muhammad Abbas and Kamran Ali and Saleem Memon and Abdul Jamali and Saleemullah Memon and Anees Ahmed},
  year = {2019},
  month = {03},
  pages = {},
  title = {Multinomial Naive Bayes Classification Model for Sentiment Analysis},
  doi = {10.13140/RG.2.2.30021.40169}
}

@inproceedings{Guia2019ComparisonON,
  title={Comparison of Naive Bayes, Support Vector Machine, Decision Trees and Random Forest on Sentiment Analysis},
  author={Marcio Guia and Rodrigo Rocha Silva and Jorge Bernardino},
  booktitle={KDIR},
  year={2019}
}

@inproceedings{hutto2015vader,
  author = {C.J. Hutto and Eric Gilbert},
  year = {2015},
  month = {01},
  pages = {},
  title = {VADER: A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text},
  journal = {Proceedings of the 8th International Conference on Weblogs and Social Media, ICWSM 2014}
}

@article{feng2019824,
  title = {Top executives on social media and information in the capital market: Evidence from China},
  journal = {Journal of Corporate Finance},
  volume = {58},
  pages = {824-857},
  year = {2019},
  issn = {0929-1199},
  doi = {https://doi.org/10.1016/j.jcorpfin.2019.04.009},
  url = {https://www.sciencedirect.com/science/article/pii/S0929119918303225},
  author = {Xunan Feng and Anders C. Johansson},
  keywords = {Social media, Information dissemination, Capital market, Investors, China}
}

@article{gu2020twtrsentiment,
  title = {Informational role of social media: Evidence from Twitter sentiment},
  journal = {Journal of Banking and Finance},
  volume = {121},
  pages = {105969},
  year = {2020},
  issn = {0378-4266},
  doi = {https://doi.org/10.1016/j.jbankfin.2020.105969},
  url = {https://www.sciencedirect.com/science/article/pii/S0378426620302314},
  author = {Chen Gu and Alexander Kurov},
  keywords = {Twitter sentiment, News sentiment, Social media, Return predictability, Analyst recommendations, Earnings forecasts, Target prices}
}

@article{mahla2019stockpriceprediction,
  author = {Mahla Nikou and Gholamreza Mansourfar and Jamshid Bagherzadeh},
  year = {2019},
  month = {12},
  pages = {},
  title = {Stock price prediction using DEEP learning algorithm and its comparison with machine learning algorithms},
  volume = {26},
  journal = {Intelligent Systems in Accounting, Finance and Management},
  doi = {10.1002/isaf.1459}
}

@article{shetty2021nonstationary,
  author = {Dileep Kumar Shetty and B. Ismail},
  title = {Forecasting stock prices using hybrid non-stationary time series model with ERNN},
  journal = {Communications in Statistics - Simulation and Computation},
  volume = {0},
  number = {0},
  pages = {1-13},
  year  = {2021},
  publisher = {Taylor & Francis},
  doi = {10.1080/03610918.2021.1872631},
  URL = {https://doi.org/10.1080/03610918.2021.1872631}
}

@article{caginalp1995arima,
  author = {Gunduz Caginalp and Gregroy M. Constantine},
  year = {1995},
  title = {Statistical inference and modelling of momentum in stock prices},
  journal = {Applied Mathematical Finance 2},
  pages = {225-242}
}

@article{chen2021meanvariance,
  title = {Mean-variance portfolio optimization using machine learning-based stock price prediction},
  journal = {Applied Soft Computing},
  volume = {100},
  pages = {106943},
  year = {2021},
  issn = {1568-4946},
  doi = {https://doi.org/10.1016/j.asoc.2020.106943},
  url = {https://www.sciencedirect.com/science/article/pii/S1568494620308814},
  author = {Wei Chen and Haoyu Zhang and Mukesh Kumar Mehlawat and Lifen Jia}
}
@article{giovanni2021word2vec,
  author = {Giovanni Gennaro and Amedeo Buonanno and Francesco Palmieri},
  year = {2021},
  month = {11},
  pages = {},
  title = {Considerations about learning Word2Vec},
  volume = {77},
  journal = {The Journal of Supercomputing},
  doi = {10.1007/s11227-021-03743-2}
}

@article{werner2004talknoise,
  author = {Werner Antweiler and  Murray Frank},
  year = {2004},
  month = {02},
  pages = {1259-1294},
  title = {Is All That Talk Just Noise? The Information Content of Internet Stock Message Boards},
  volume = {59},
  journal = {Journal of Finance},
  doi = {10.2139/ssrn.282320}
}

@article{rammurthy2021lstm,
  author = {Shruthi K. Rammurthy and Sagar B. Patil},
  title = {An LSTM-Based Approach to Predict Stock Price Movement for IT Sector Companies},
  journal = {International Journal of Cognitive Informatics and Natural Intelligence},
  year = {2021},
  volume = {15},
  issue = {4},
  pages = {1-12}
}

@article{gooijer2006forecasting,
  author = {Jan G. {De Gooijer} and Rob Hyndman},
  year = {2006},
  pages = {443-473},
  title = {25 Years of time series forecasting},
  volume = {22},
  journal = {International Journal of Forecasting},
  doi = {10.1016/j.ijforecast.2006.01.001}
}

@article{jin2020lstmsentiment,
  author = {Zhigang Jin and Yang Yang and Yuhong Liu},
  year = {2020},
  pages = {},
  title = {Stock closing price prediction based on sentiment analysis and LSTM},
  volume = {32},
  journal = {Neural Computing and Applications},
  doi = {10.1007/s00521-019-04504-2}
}


@article{vuong2021forecasting,
  author = {Pham Hoang Vuong and Trinh Tan Dat and Tieu Khoi Mai and Pham Hoang Uyen and Pham The Bao},
  title = {Stock-Price Forecasting Based on XGBoost and LSTM},
  journal = {Computer Systems Science and Engineering},
  volume = {40},
  year = {2021},
  pages = {237-246},
  url = {http://www.techscience.com/csse/v40n1/44219},
  doi = {10.32604/csse.2022.017685}
}

@article{ivanovic2013arima,
  author={Zoran Ivanovic and Sinisa Bogdan and Suzana Baresa},
  year={2013},
  month={06},
  title={FORECASTING CROATIAN STOCK MARKET INDEX: CROBEX},
  journal={UTMS Journal of Economics},
  volume={4},
  number={2},
  pages={79-91},
  url={https://www.proquest.com/scholarly-journals/forecasting-croatian-stock-market-index-crobex/docview/1399281625/se-2}
}

@article{chousa2017socialmedia,
  author = {Juan Piñeiro-Chousa and Marcos Vizcaino-Gonzalez and Ada M. Perez-Pico},
  year = {2017},
  pages = {101-108},
  title = {Influence of Social Media over the Stock Market},
  volume = {34},
  journal = {Psychology and Marketing},
  doi = {10.1002/mar.20976}
}

@article{bo2008opinionmining, 
  author = {Bo Pang and Lillian Lee},
  title = {Opinion Mining and Sentiment Analysis},
  year = {2008},
  publisher = {Now Publishers Inc.},
  address = {Hanover, MA, USA},
  volume = {2},
  issn = {1554-0669},
  url = {https://doi.org/10.1561/1500000011},
  doi = {10.1561/1500000011},
  journal = {Found. Trends Inf. Retr.}, 
  pages = {1-135}
}

@inproceedings{wang2012NB,
  author = {Sida Wang and Christopher Manning},
  year = {2012},
  month = {07},
  pages = {90-94},
  title = {Baselines and Bigrams: Simple, Good Sentiment and Topic Classification}
}

@inproceedings{omar2019conference,  
  author={Omar Sharif and Mohammed Moshiul Hoque and Eftekhar Hossain},  
  booktitle={2019 1st International Conference on Advances in Science, Engineering and Robotics Technology (ICASERT)},
  title={Sentiment Analysis of Bengali Texts on Online Restaurant Reviews Using Multinomial Naïve Bayes},
  year={2019},
  pages={1-6},
  doi={10.1109/ICASERT.2019.8934655}
}

@article{susanti2017sentiment,
  author = {Aisah Susanti and Taufik Djatna and Wisnu Kusuma},
  year = {2017},
  month = {09},
  pages = {1354-1361},
  title = {Twitter's Sentiment Analysis on Gsm Services using Multinomial Naïve Bayes},
  volume = {15},
  journal = {Telkomnika (Telecommunication Computing Electronics and Control)},
  doi = {10.12928/TELKOMNIKA.v15i3.4284}
}

@article{schoneburg1990prediction,
  title = {Stock price prediction using neural networks: A project report},
  journal = {Neurocomputing},
  volume = {2},
  number = {1},
  pages = {17-27},
  year = {1990},
  issn = {0925-2312},
  doi = {https://doi.org/10.1016/0925-2312(90)90013-H},
  url = {https://www.sciencedirect.com/science/article/pii/092523129090013H},
  author = {Eberhard Schöneburg}
}

@INPROCEEDINGS{wang2019forecasting,
  author={He Wang and Zhiqiang Guo and Lijun Chen},
  booktitle={2019 IEEE 8th Joint International Information Technology and Artificial Intelligence Conference (ITAIC)},
  title={Financial Forecasting based on LSTM and Text Emotional Features},
  year={2019},
  pages={1427-1430},
  doi={10.1109/ITAIC.2019.8785505}
}

@inproceedings{schnabel2015embeddings,
  author = {Tobias Schnabel and Igor Labutov and David Mimno and Thorsten Joachims},
  year = {2015},
  month = {01},
  pages = {298-307},
  title = {Evaluation methods for unsupervised word embeddings},
  doi = {10.18653/v1/D15-1036}
}

@INPROCEEDINGS{sima2018timeseries,
  author={Sima Siami-Namini and Neda Tavakoli and Akbar Siami-Namin},
  booktitle={2018 17th IEEE International Conference on Machine Learning and Applications (ICMLA)},
  title={A Comparison of ARIMA and LSTM in Forecasting Time Series},
  year={2018},
  volume={},
  number={},
  pages={1394-1401},
  doi={10.1109/ICMLA.2018.00227}
}

@article{jain2017ASO,
  title={A Study of Time Series Models ARIMA and ETS},
  author={Garima Jain and Bhawna Mallick},
  year={2017}
}

@INPROCEEDINGS{preeti2019lstm,
  author={Preeti and Rajni Bala and Ram Pal Singh},
  booktitle={2019 10th International Conference on Computing, Communication and Networking Technologies (ICCCNT)},
  title={Financial and Non-Stationary Time Series Forecasting using LSTM Recurrent Neural Network for Short and Long Horizon},
  year={2019},
  volume={},
  number={},
  pages={1-7},
  doi={10.1109/ICCCNT45670.2019.8944624}
}

@inproceedings{hai2020lstms,
  author = {Pham Ngoc Hai and Nguyen Manh Tien and Hoang Trung Hieu and Pham Quoc Chung and Nguyen Thanh Son and Pham Ngoc Ha and Ngo Tung Son},
  title = {An Empirical Research on the Effectiveness of Different LSTM Architectures on Vietnamese Stock Market},
  year = {2020},
  isbn = {9781450388054},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3437802.3437827},
  doi = {10.1145/3437802.3437827},
  abstract = {Stock price prediction is a challenging financial time-series forecasting problem. In recent years, on account of the rapid progression of deep learning, researchers have developed highly accurate, state-of-the-art time-series models. Long short-term memory (LSTM) stands out as one of the most reliable architecture at capturing long-time temporal dependences. In Vietnam, there is a lack of research papers that solely focused on the effectiveness of deep-learning in stock price prediction. This paper surveys three different variations of LSTM (Vanilla, Stacked, Bidirectional) when applied to 20 companies’ stock prices over a period of 5 years from 2015 to 2020 in the VN-index stock exchange. The results show that Bidirectional LSTM is the most accurate model.},
  booktitle = {2020 International Conference on Control, Robotics and Intelligent System},
  pages = {144-149},
  numpages = {6},
  keywords = {Stock Price Prediction, Bidirectional LSTM, Vanilla LSTM, LSTM, Stacked LSTM},
  location = {Xiamen, China},
  series = {CCRIS 2020}
}

@InProceedings{liu2019multivariate,
  author={Jiexi Liu and Chen Songcan},
  editor={Abhaya C. Nayak and Alok Sharma},
  title={Non-stationary Multivariate Time Series Prediction with Selective Recurrent Neural Networks},
  booktitle={PRICAI 2019: Trends in Artificial Intelligence},
  year={2019},
  publisher={Springer International Publishing},
  address={Cham},
  pages={636-649}
}

@article{rezaei2021stockpriceprediction,
  title = {Stock price prediction using deep learning and frequency decomposition},
  author = {Hadi Rezaei and Hamidreza Faaljou and Gholamreza Mansourfar},
  journal = {Expert Systems with Applications},
  volume = {169},
  year = {2021},
  issn = {0957-4174},
  doi = {https://doi.org/10.1016/j.eswa.2020.114332},
  url = {https://www.sciencedirect.com/science/article/pii/S0957417420310228}
}

@article{hossin2015evaluationmetrics,
  author = {Mohammad Hossin and M N Sulaiman},
  year = {2015},
  month = {03},
  pages = {1-11},
  title = {A Review on Evaluation Metrics for Data Classification Evaluations},
  volume = {5},
  journal = {International Journal of Data Mining and Knowledge Management Process}
}

@article{saud2020lookback,
  title = {Analysis of look back period for stock price prediction with RNN variants: A case study on banking sector of NEPSE},
  journal = {Procedia Computer Science},
  volume = {167},
  pages = {788-798},
  year = {2020},
  note = {International Conference on Computational Intelligence and Data Science},
  issn = {1877-0509},
  doi = {https://doi.org/10.1016/j.procs.2020.03.419},
  url = {https://www.sciencedirect.com/science/article/pii/S1877050920308851},
  author = {Arjun Singh Saud and Subarna Shakya}
}

@article{lim2020lookback,
   title={Time-series forecasting with deep learning: a survey},
   volume={379},
   ISSN={1471-2962},
   url={http://dx.doi.org/10.1098/rsta.2020.0209},
   DOI={10.1098/rsta.2020.0209},
   number={2194},
   journal={Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
   publisher={The Royal Society},
   author={Bryan Lim and Stefan Zohren},
   year={2020},
   month={Feb}
}

@article{sahu2017stratification,
  author = {Manish Sahu and Anirban Mukhopadhyay and Angelika Szengel and Stefan Zachow},
  year = {2017},
  month = {03},
  title = {Addressing multi-label imbalance problem of surgical tool detection using CNN},
  volume = {12},
  journal = {International journal of computer assisted radiology and surgery},
  doi = {10.1007/s11548-017-1565-x}
}

@INPROCEEDINGS{jason2021tfidf,
  author={Jason Cornelius Sugitomo and Nathaniel Kevin and Nayra Jannatri and Derwin Suhartono},
  booktitle={2021 1st International Conference on Computer Science and Artificial Intelligence (ICCSAI)}, 
  title={Sentiment Analysis using SVM and Naïve Bayes Classifiers on Restaurant Review Dataset}, 
  year={2021},
  volume={1},
  number={},
  pages={100-108},
  doi={10.1109/ICCSAI53272.2021.9609776}
}

@article{ganganwar2012overview,
  title={An overview of classification algorithms for imbalanced datasets},
  author={Vaishali Ganganwar},
  journal={International Journal of Emerging Technology and Advanced Engineering},
  volume={2},
  number={4},
  pages={42-47},
  year={2012},
  publisher={Citeseer}
}